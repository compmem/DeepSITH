{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T03:06:21.424413Z",
     "start_time": "2020-11-30T03:06:21.240186Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T03:06:22.360015Z",
     "start_time": "2020-11-30T03:06:21.787667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "sn.set_context(\"poster\")\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from cornn import coRNN\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "import scipy.special\n",
    "import scipy.signal\n",
    "import scipy.interpolate\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from os.path import join\n",
    "import random\n",
    "from csv import DictWriter\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "# if gpu is to be used\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "DoubleTensor = torch.cuda.DoubleTensor if use_cuda else torch.DoubleTensor\n",
    "IntTensor = torch.cuda.IntTensor if use_cuda else torch.IntTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "ttype = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T03:06:22.810622Z",
     "start_time": "2020-11-30T03:06:22.806883Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def get_batch(batch_size, T, ttype):\n",
    "    values = torch.rand(T, batch_size, requires_grad=False)\n",
    "    indices = torch.zeros_like(values)\n",
    "    half = int(T / 2)\n",
    "    for i in range(batch_size):\n",
    "        half_1 = np.random.randint(half)\n",
    "        hals_2 = np.random.randint(half, T)\n",
    "        indices[half_1, i] = 1\n",
    "        indices[hals_2, i] = 1\n",
    "\n",
    "    data = torch.stack((values, indices), dim=-1).type(ttype)\n",
    "    targets = torch.mul(values, indices).sum(dim=0).type(ttype)\n",
    "    return data, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T03:06:25.221560Z",
     "start_time": "2020-11-30T03:06:23.421596Z"
    }
   },
   "outputs": [],
   "source": [
    "inp, _ = get_batch(4,500,ttype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T03:06:25.225674Z",
     "start_time": "2020-11-30T03:06:25.222491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe40a4608f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T03:06:26.997683Z",
     "start_time": "2020-11-30T03:06:26.986559Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, ttype, seq_length, optimizer, loss_func, \n",
    "          epoch, perf_file, loss_buffer_size=20, batch_size=1, test_size=10,\n",
    "          device='cuda', prog_bar=None):\n",
    "    assert(loss_buffer_size%batch_size==0)\n",
    "\n",
    "    losses = []\n",
    "    perfs = []\n",
    "    last_test_perf = 0\n",
    "    for batch_idx in range(20000):\n",
    "        model.train()\n",
    "        sig, target = get_batch(batch_size, seq_length, ttype=ttype)\n",
    "        \n",
    "        target = target.unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(sig)\n",
    "        loss = loss_func(out,\n",
    "                         target)\n",
    "         \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        losses = losses[-loss_buffer_size:]\n",
    "        if not (prog_bar is None):\n",
    "            # Update progress_bar\n",
    "            s = \"{}:{} Loss: {:.8f}\"\n",
    "            format_list = [e, int(batch_idx/(50/batch_size)), np.mean(losses)]         \n",
    "            s = s.format(*format_list)\n",
    "            prog_bar.set_description(s)\n",
    "        if ((batch_idx*batch_size)%loss_buffer_size == 0) & (batch_idx != 0):\n",
    "            loss_track = {}\n",
    "            #last_test_perf = test_norm(model, 'cuda', test_sig, test_class,\n",
    "            #                                    batch_size=test_size, \n",
    "            #                                    )\n",
    "            loss_track['avg_loss'] = np.mean(losses)\n",
    "            #loss_track['last_test'] = last_test_perf\n",
    "            loss_track['epoch'] = epoch\n",
    "            loss_track['batch_idx'] = batch_idx\n",
    "            with open(perf_file, 'a+') as fp:\n",
    "                csv_writer = DictWriter(fp, fieldnames=list(loss_track.keys()))\n",
    "                if fp.tell() == 0:\n",
    "                    csv_writer.writeheader()\n",
    "                csv_writer.writerow(loss_track)\n",
    "                fp.flush()\n",
    "def test_norm(model, device, seq_length, loss_func, batch_size=100):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        sig, target = get_batch(batch_size, seq_length, ttype=ttype)\n",
    "        target = target.unsqueeze(1)\n",
    "        out = model(sig)\n",
    "        loss = loss_func(out,\n",
    "                         target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T03:06:27.626073Z",
     "start_time": "2020-11-30T03:06:27.616278Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class coRNNCell(nn.Module):\n",
    "    def __init__(self, n_inp, n_hid, dt, gamma, epsilon):\n",
    "        super(coRNNCell, self).__init__()\n",
    "        self.dt = dt\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.i2h = nn.Linear(n_inp + n_hid + n_hid, n_hid)\n",
    "\n",
    "    def forward(self,x,hy,hz):\n",
    "        hz = hz + self.dt * (torch.tanh(self.i2h(torch.cat((x, hz, hy),1)))\n",
    "                                   - self.gamma * hy - self.epsilon * hz)\n",
    "        hy = hy + self.dt * hz\n",
    "\n",
    "        return hy, hz\n",
    "\n",
    "class coRNN(nn.Module):\n",
    "    def __init__(self, n_inp, n_hid, n_out, dt, gamma, epsilon):\n",
    "        super(coRNN, self).__init__()\n",
    "        self.n_hid = n_hid\n",
    "        self.cell = coRNNCell(n_inp,n_hid,dt,gamma,epsilon)\n",
    "        self.readout = nn.Linear(n_hid, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## initialize hidden states\n",
    "        hy = Variable(torch.zeros(x.size(1),self.n_hid)).to(device)\n",
    "        hz = Variable(torch.zeros(x.size(1),self.n_hid)).to(device)\n",
    "\n",
    "        for t in range(x.size(0)):\n",
    "            hy, hz = self.cell(x[t],hy,hz)\n",
    "        output = self.readout(hy)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T03:06:30.537167Z",
     "start_time": "2020-11-30T03:06:30.532295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Weights: 33281\n",
      "coRNN(\n",
      "  (cell): coRNNCell(\n",
      "    (i2h): Linear(in_features=258, out_features=128, bias=True)\n",
      "  )\n",
      "  (readout): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cornn_params = dict(n_inp=2,\n",
    "                    n_hid=128, \n",
    "                    n_out=1,\n",
    "                    dt=6e-2,\n",
    "                    gamma=66,\n",
    "                    epsilon=15)\n",
    "model = coRNN(**cornn_params).cuda()\n",
    "\n",
    "tot_weights = 0\n",
    "for p in model.parameters():\n",
    "    tot_weights += p.numel()\n",
    "print(\"Total Weights:\", tot_weights)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T16:56:08.788295Z",
     "start_time": "2020-11-18T16:56:08.694417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 4, 2]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "print(inp.shape, model(inp).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T14:59:29.309099Z",
     "start_time": "2020-11-18T16:56:09.297241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8d8ac070654d228103bb5e7908ac92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e73fbc9d248d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprogress_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbar_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{l_bar}{bar:5}{r_bar}{bar:-5b}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     train(model, ttype, seq_length,\n\u001b[1;32m      9\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_buffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminiters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminiters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;31m# Try to detect if there was an error or KeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# in manual mode: if n < total, things probably got wrong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;31m# decrement instance pos and remove from internal set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decr_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0;31m# GUI mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m_decr_instances\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instances\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m                     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m                     \u001b[0;32mdel\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: nocover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/tqdm/_monitor.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwas_killed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcurrent_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seq_length=500\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-2)\n",
    "epochs = 1\n",
    "progress_bar = tqdm(range(int(epochs)), bar_format='{l_bar}{bar:5}{r_bar}{bar:-5b}')\n",
    "for e in progress_bar:\n",
    "    train(model, ttype, seq_length,\n",
    "          optimizer, loss_func, batch_size=50, loss_buffer_size=100,\n",
    "          epoch=e, perf_file=join('perf','adding500_cornn_2.csv'),\n",
    "          prog_bar=progress_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T14:59:29.310299Z",
     "start_time": "2020-11-18T17:07:06.025Z"
    }
   },
   "outputs": [],
   "source": [
    "cornn_params = dict(n_inp=2,\n",
    "                    n_hid=128, \n",
    "                    n_out=1,\n",
    "                    dt=6e-2,\n",
    "                    gamma=66,\n",
    "                    epsilon=15)\n",
    "model = coRNN(**cornn_params).cuda()\n",
    "\n",
    "tot_weights = 0\n",
    "for p in model.parameters():\n",
    "    tot_weights += p.numel()\n",
    "print(\"Total Weights:\", tot_weights)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T14:59:29.310823Z",
     "start_time": "2020-11-18T17:07:08.072Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_length=2000\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-2)\n",
    "epochs = 1\n",
    "progress_bar = tqdm(range(int(epochs)), bar_format='{l_bar}{bar:5}{r_bar}{bar:-5b}')\n",
    "for e in progress_bar:\n",
    "    train(model, ttype, seq_length,\n",
    "          optimizer, loss_func, batch_size=50, loss_buffer_size=100,\n",
    "          epoch=e, perf_file=join('perf','adding2000_cornn_1.csv'),\n",
    "          prog_bar=progress_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  T = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T14:59:29.311333Z",
     "start_time": "2020-11-18T17:07:11.892Z"
    }
   },
   "outputs": [],
   "source": [
    "cornn_params = dict(n_inp=2,\n",
    "                    n_hid=128, \n",
    "                    n_out=1,\n",
    "                    dt=6e-2,\n",
    "                    gamma=66,\n",
    "                    epsilon=15)\n",
    "model = coRNN(**cornn_params).cuda()\n",
    "\n",
    "tot_weights = 0\n",
    "for p in model.parameters():\n",
    "    tot_weights += p.numel()\n",
    "print(\"Total Weights:\", tot_weights)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T14:59:29.311814Z",
     "start_time": "2020-11-18T17:07:12.867Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_length=5000\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-2)\n",
    "epochs = 1\n",
    "progress_bar = tqdm(range(int(epochs)), bar_format='{l_bar}{bar:5}{r_bar}{bar:-5b}')\n",
    "for e in progress_bar:\n",
    "    train(model, ttype, seq_length,\n",
    "          optimizer, loss_func, batch_size=50, loss_buffer_size=100,\n",
    "          epoch=e, perf_file=join('perf','adding5000_cornn_1.csv'),\n",
    "          prog_bar=progress_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T14:59:29.312309Z",
     "start_time": "2020-11-18T17:07:42.345Z"
    }
   },
   "outputs": [],
   "source": [
    "dat = pd.read_csv(os.path.join('perf', 'adding500_cornn_2.csv'))\n",
    "dat2 = pd.read_csv(os.path.join('perf', 'adding2000_cornn_2.csv'))\n",
    "dat3 = pd.read_csv(os.path.join('perf', 'adding5000_cornn_1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T14:56:35.423315Z",
     "start_time": "2020-11-12T14:56:35.413282Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T14:59:29.312917Z",
     "start_time": "2020-11-18T17:07:43.056Z"
    }
   },
   "outputs": [],
   "source": [
    "dat['training_step'] = (dat.batch_idx)/100\n",
    "dat2['training_step'] = (dat2.batch_idx)/100\n",
    "dat3['training_step'] = (dat3.batch_idx)*10/5/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-19T14:59:29.313431Z",
     "start_time": "2020-11-18T17:07:44.263Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "sn.lineplot(data=dat, x=dat.training_step, y=dat.avg_loss,)\n",
    "sn.lineplot(data=dat2, x=dat2.training_step, y=dat2.avg_loss,)\n",
    "ax = sn.lineplot(data=dat3, x=dat3.training_step, y=dat3.avg_loss,)\n",
    "plt.legend(['T=500', 'T=2000', 'T=5000'])\n",
    "ax.set_xlabel('Training steps (hundreds)')\n",
    "ax.set_ylabel('Average Loss')\n",
    "ax.set_xlim(0, 150)\n",
    "ax.set_ylim(0, .2)\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "nav_menu": {
    "height": "141px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
