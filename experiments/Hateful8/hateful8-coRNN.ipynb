{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T15:27:24.026352Z",
     "start_time": "2020-12-18T15:27:23.777350Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T15:27:24.607154Z",
     "start_time": "2020-12-18T15:27:24.027343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from math import factorial\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import os \n",
    "from os.path import join\n",
    "import glob\n",
    "from math import factorial\n",
    "ttype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "ctype = torch.cuda.LongTensor if torch.cuda.is_available() else torch.LongTensor\n",
    "print(ttype)\n",
    "from torch.nn.utils import weight_norm\n",
    "from cornn import coRNN\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "sn.set_context(\"poster\")\n",
    "import itertools\n",
    "from csv import DictWriter\n",
    "import matplotlib.pylab as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sn\n",
    "sn.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T16:59:44.351074Z",
     "start_time": "2020-12-18T16:59:44.277936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f18f00b3128>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_noise(maxn=18):\n",
    "    \"\"\"Generates dot and dash based noise.\"\"\"\n",
    "    \n",
    "    threes = np.random.randint(int(.5*maxn), int(.75*maxn))\n",
    "    ones = (maxn - threes) * 2\n",
    "    noise = list(itertools.repeat([1,1,1,0], threes))\n",
    "    noise[:int(len(noise)/3)] = list(itertools.repeat([0,0], int(len(noise)/3)))\n",
    "    ones = ones + int(len(noise)/3)\n",
    "    noise.extend(list(itertools.repeat([1,0], ones)))\n",
    "    random.shuffle(noise)\n",
    "    noise = np.concatenate(noise)\n",
    "    return noise\n",
    "noise = generate_noise(6)\n",
    "print(noise.shape)\n",
    "plt.plot(noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T15:32:01.198628Z",
     "start_time": "2020-12-18T15:31:59.311792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7}\n"
     ]
    }
   ],
   "source": [
    "sig_lets = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",]\n",
    "\n",
    "signals = ttype([[0,1,1,1,0,1,1,1,0,1,0,1,0,1,0,0,0],\n",
    "                 [0,1,1,1,0,1,0,1,1,1,0,1,0,1,0,0,0],\n",
    "                 [0,1,1,1,0,1,0,1,0,1,1,1,0,1,0,0,0],\n",
    "                 [0,1,1,1,0,1,0,1,0,1,0,1,1,1,0,0,0],\n",
    "                 [0,1,0,1,1,1,0,1,1,1,0,1,1,1,0,0,0],\n",
    "                 [0,1,1,1,0,1,0,1,1,1,0,1,1,1,0,0,0],\n",
    "                 [0,1,1,1,0,1,1,1,0,1,0,1,1,1,0,0,0],\n",
    "                 [0,1,1,1,0,1,1,1,0,1,1,1,0,1,0,0,0]]\n",
    "               ).view(8, 1, 1, -1)\n",
    "#signals = ms\n",
    "key2id = {k:i for i, k in enumerate(sig_lets)}\n",
    "\n",
    "print(key2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:04:21.027517Z",
     "start_time": "2020-12-11T19:04:20.859937Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "np.random.seed(12345)\n",
    "\n",
    "training_samples = 32\n",
    "\n",
    "training_signals = []\n",
    "training_class = []\n",
    "\n",
    "for i, sig in enumerate(signals):\n",
    "    temp_signals = []\n",
    "    temp_class = []\n",
    "    for x in range(training_samples):\n",
    "        noise = ttype(generate_noise())\n",
    "        temp = torch.cat([sig[0,0], noise]).unsqueeze(0)\n",
    "        while(any([(temp == c_).all() for c_ in temp_signals])):\n",
    "            print('SHIT')\n",
    "            noise = ttype(generate_noise())\n",
    "            temp = torch.cat([sig[0,0], noise]).unsqueeze(0)\n",
    "        temp_signals.append(temp)\n",
    "        temp_class.append(i)\n",
    "    training_signals.extend(temp_signals)\n",
    "    training_class.extend(temp_class)\n",
    "\n",
    "batch_rand = torch.randperm(training_samples*signals.shape[0])        \n",
    "training_signals = torch.cat(training_signals).cuda().unsqueeze(-1)[batch_rand]\n",
    "training_class  = ctype(training_class).cuda().unsqueeze(-1)[batch_rand]\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(training_signals, training_class)\n",
    "dataset = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:04:22.408355Z",
     "start_time": "2020-12-11T19:04:21.765214Z"
    }
   },
   "outputs": [],
   "source": [
    "testing_samples = 10\n",
    "testing_signals = []\n",
    "testing_class = []\n",
    "\n",
    "for i, sig in enumerate(signals):\n",
    "    temp_signals = []\n",
    "    temp_class = []\n",
    "    for x in range(testing_samples):\n",
    "        noise = ttype(generate_noise())\n",
    "        temp = torch.cat([sig[0,0], noise]).unsqueeze(0)\n",
    "        while(any([(temp == c_).all() for c_ in temp_signals]) or any([(temp == c_).all() for c_ in training_signals])):\n",
    "            print('SHIT')\n",
    "            noise = ttype(generate_noise())\n",
    "            temp = torch.cat([sig[0,0], noise]).unsqueeze(0)\n",
    "        temp_signals.append(temp)\n",
    "        temp_class.append(i)\n",
    "    testing_signals.extend(temp_signals)\n",
    "    testing_class.extend(temp_class)\n",
    "batch_rand = torch.randperm(testing_samples*signals.shape[0])\n",
    "\n",
    "testing_signals = torch.cat(testing_signals).cuda().unsqueeze(-1)[batch_rand]\n",
    "testing_class  = ctype(testing_class).cuda().unsqueeze(-1)[batch_rand]\n",
    "\n",
    "\n",
    "dataset_valid = torch.utils.data.TensorDataset(testing_signals, testing_class)\n",
    "dataset_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T15:34:34.380991Z",
     "start_time": "2020-12-18T15:34:34.374028Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class coRNNCell(nn.Module):\n",
    "    def __init__(self, n_inp, n_hid, dt, gamma, epsilon):\n",
    "        super(coRNNCell, self).__init__()\n",
    "        self.dt = dt\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.i2h = nn.Linear(n_inp + n_hid + n_hid, n_hid)\n",
    "\n",
    "    def forward(self,x,hy,hz):\n",
    "        hz = hz + self.dt * (torch.tanh(self.i2h(torch.cat((x, hz, hy),1)))\n",
    "                                   - self.gamma * hy - self.epsilon * hz)\n",
    "        hy = hy + self.dt * hz\n",
    "\n",
    "        return hy, hz\n",
    "\n",
    "class coRNN(nn.Module):\n",
    "    def __init__(self, n_inp, n_hid, n_out, dt, gamma, epsilon):\n",
    "        super(coRNN, self).__init__()\n",
    "        self.n_hid = n_hid\n",
    "        self.cell = coRNNCell(n_inp,n_hid,dt,gamma,epsilon)\n",
    "        self.readout = nn.Linear(n_hid, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## initialize hidden states\n",
    "        hy = Variable(torch.zeros(x.size(1),self.n_hid)).to(device)\n",
    "        hz = Variable(torch.zeros(x.size(1),self.n_hid)).to(device)\n",
    "\n",
    "        for t in range(x.size(0)):\n",
    "            hy, hz = self.cell(x[t],hy,hz)\n",
    "        output = self.readout(hy)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T15:31:49.579761Z",
     "start_time": "2020-12-18T15:31:49.537804Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, ttype, train_loader, test_loader, optimizer, loss_func, epoch, perf_file,\n",
    "          permute=None, loss_buffer_size=64, batch_size=4, device='cuda',\n",
    "          prog_bar=None, maxn=6):\n",
    "    \n",
    "    assert(loss_buffer_size%batch_size==0)\n",
    "        \n",
    "    losses = []\n",
    "    perfs = []\n",
    "    last_test_perf = 0\n",
    "    best_test_perf = -1\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        data = data.to(device).transpose(1,0)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_func(out,\n",
    "                         target[:, 0])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        perfs.append((torch.argmax(out, dim=-1) == \n",
    "                      target[:, 0]).sum().item())\n",
    "        perfs = perfs[int(-loss_buffer_size/batch_size):]\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        losses = losses[int(-loss_buffer_size/batch_size):]\n",
    "        if not (prog_bar is None):\n",
    "            # Update progress_bar\n",
    "            s = \"{}:{} Loss: {:.4f}, perf: {:.4f}, valid: {:.4f}\"\n",
    "            format_list = [e,batch_idx*batch_size, np.mean(losses), \n",
    "                           np.sum(perfs)/((len(perfs))*batch_size), last_test_perf]         \n",
    "            s = s.format(*format_list)\n",
    "            prog_bar.set_description(s)\n",
    "        \n",
    "        if ((batch_idx*batch_size)%loss_buffer_size == 0) & (batch_idx != 0):\n",
    "            loss_track = {}\n",
    "            last_test_perf = test(model, 'cuda', test_loader, \n",
    "                                  batch_size=batch_size, \n",
    "                                  permute=permute)\n",
    "            loss_track['avg_loss'] = np.mean(losses)\n",
    "            loss_track['last_test'] = last_test_perf\n",
    "            loss_track['epoch'] = epoch\n",
    "            loss_track['maxn'] = maxn\n",
    "            loss_track['pres_num'] = batch_idx*batch_size + epoch*len(train_loader.dataset)\n",
    "            loss_track['batch_idx'] = batch_idx\n",
    "            loss_track['train_perf']= np.sum(perfs)/((len(perfs))*batch_size)\n",
    "            with open(perf_file, 'a+') as fp:\n",
    "                csv_writer = DictWriter(fp, fieldnames=list(loss_track.keys()))\n",
    "                if fp.tell() == 0:\n",
    "                    csv_writer.writeheader()\n",
    "                csv_writer.writerow(loss_track)\n",
    "                fp.flush()\n",
    "            if best_test_perf < last_test_perf:\n",
    "                torch.save(model.state_dict(), perf_file[:-4]+\".pt\")\n",
    "                best_test_perf = last_test_perf\n",
    "\n",
    "                \n",
    "def test(model, device, test_loader, batch_size=4, permute=None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device).transpose(1,0)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=-1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            count += 1\n",
    "    return correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:04:27.076414Z",
     "start_time": "2020-12-11T19:04:27.074155Z"
    }
   },
   "outputs": [],
   "source": [
    "# You likely don't need this to be this long, but just in case.\n",
    "epochs = 1000\n",
    "\n",
    "# Just for visualizing average loss through time. \n",
    "loss_buffer_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T16:18:35.148505Z",
     "start_time": "2020-12-18T16:12:42.043160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Weights: 32760\n",
      "coRNN(\n",
      "  (cell): coRNNCell(\n",
      "    (i2h): Linear(in_features=251, out_features=125, bias=True)\n",
      "  )\n",
      "  (readout): Linear(in_features=125, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733661465b3c4869b6ed641674dccee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-38d2eb3f5791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mprogress_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbar_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{l_bar}{bar:5}{r_bar}{bar:-5b}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         train(model, ttype, dataset, dataset_valid, \n\u001b[1;32m     78\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminiters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminiters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;31m# Try to detect if there was an error or KeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# in manual mode: if n < total, things probably got wrong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;31m# decrement instance pos and remove from internal set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decr_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0;31m# GUI mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m_decr_instances\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instances\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m                     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m                     \u001b[0;32mdel\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: nocover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/site-packages/tqdm/_monitor.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwas_killed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcurrent_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_noise_lengths = [6,7,9,13,21,37]\n",
    "for maxn in test_noise_lengths:\n",
    "    torch.manual_seed(12345)\n",
    "    np.random.seed(12345)\n",
    "\n",
    "    training_samples = 32\n",
    "\n",
    "    training_signals = []\n",
    "    training_class = []\n",
    "\n",
    "    for i, sig in enumerate(signals):\n",
    "        temp_signals = []\n",
    "        temp_class = []\n",
    "        for x in range(training_samples):\n",
    "            noise = ttype(generate_noise(maxn))\n",
    "            temp = torch.cat([sig[0,0], noise]).unsqueeze(0)\n",
    "            while(any([(temp == c_).all() for c_ in temp_signals])):\n",
    "                noise = ttype(generate_noise(maxn))\n",
    "                temp = torch.cat([sig[0,0], noise]).unsqueeze(0)\n",
    "            temp_signals.append(temp)\n",
    "            temp_class.append(i)\n",
    "        training_signals.extend(temp_signals)\n",
    "        training_class.extend(temp_class)\n",
    "\n",
    "    batch_rand = torch.randperm(training_samples*signals.shape[0])        \n",
    "    training_signals = torch.cat(training_signals).cuda().unsqueeze(-1)[batch_rand]\n",
    "    training_class  = ctype(training_class).cuda().unsqueeze(-1)[batch_rand]\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(training_signals, training_class)\n",
    "    dataset = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    testing_samples = 10\n",
    "    testing_signals = []\n",
    "    testing_class = []\n",
    "\n",
    "    for i, sig in enumerate(signals):\n",
    "        temp_signals = []\n",
    "        temp_class = []\n",
    "        for x in range(testing_samples):\n",
    "            noise = ttype(generate_noise(maxn))\n",
    "            temp = torch.cat([sig[0,0], noise]).unsqueeze(0)\n",
    "            while(any([(temp == c_).all() for c_ in temp_signals]) or any([(temp == c_).all() for c_ in training_signals])):\n",
    "                noise = ttype(generate_noise(maxn))\n",
    "                temp = torch.cat([sig[0,0], noise]).unsqueeze(0)\n",
    "            temp_signals.append(temp)\n",
    "            temp_class.append(i)\n",
    "        testing_signals.extend(temp_signals)\n",
    "        testing_class.extend(temp_class)\n",
    "    batch_rand = torch.randperm(testing_samples*signals.shape[0])\n",
    "\n",
    "    testing_signals = torch.cat(testing_signals).cuda().unsqueeze(-1)[batch_rand]\n",
    "    testing_class  = ctype(testing_class).cuda().unsqueeze(-1)[batch_rand]\n",
    "\n",
    "\n",
    "    dataset_valid = torch.utils.data.TensorDataset(testing_signals, testing_class)\n",
    "    dataset_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=32, shuffle=False)\n",
    "    cornn_params = dict(n_inp=1,\n",
    "                        n_hid=125, \n",
    "                        n_out=10,\n",
    "                        dt=.076,\n",
    "                        gamma=.4,\n",
    "                        epsilon=8)\n",
    "    model = coRNN(**cornn_params).cuda()\n",
    "\n",
    "    tot_weights = 0\n",
    "    for p in model.parameters():\n",
    "        tot_weights += p.numel()\n",
    "    print(\"Total Weights:\", tot_weights)\n",
    "    print(model)\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=.0054)\n",
    "    epochs = 400\n",
    "    batch_size = 32\n",
    "    progress_bar = tqdm(range(int(epochs)), bar_format='{l_bar}{bar:5}{r_bar}{bar:-5b}')\n",
    "    for e in progress_bar:\n",
    "        train(model, ttype, dataset, dataset_valid, \n",
    "              optimizer, loss_func, batch_size=batch_size,\n",
    "              epoch=e, perf_file=join('perf','h8_cornn_length_2.csv'),\n",
    "              prog_bar=progress_bar, maxn=maxn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
