{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T16:15:36.355232Z",
     "start_time": "2021-01-31T16:15:36.174356Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T16:15:37.469291Z",
     "start_time": "2021-01-31T16:15:36.530387Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm_notebook\n",
    "import PIL\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.autograd import Variable\n",
    "import nengolib\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from os.path import join\n",
    "import scipy.special\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import scipy\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.interpolate import interp1d\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "from csv import DictWriter\n",
    "from lmu import LegendreMemoryUnit\n",
    "\n",
    "# if gpu is to be used\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "DoubleTensor = torch.cuda.DoubleTensor if use_cuda else torch.DoubleTensor\n",
    "\n",
    "IntTensor = torch.cuda.IntTensor if use_cuda else torch.IntTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n",
    "ttype = FloatTensor\n",
    "\n",
    "import seaborn as sns\n",
    "print(use_cuda)\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T16:15:41.303102Z",
     "start_time": "2021-01-31T16:15:41.299727Z"
    }
   },
   "outputs": [],
   "source": [
    "class LMUModel(nn.Module):\n",
    "    def __init__(self, n_out, layer_params):\n",
    "        super(LMUModel, self).__init__()\n",
    "        self.layers = nn.ModuleList([LegendreMemoryUnit(**layer_params[i])\n",
    "                                      for i in range(len(layer_params))])\n",
    "        self.dense = nn.Linear(layer_params[-1]['hidden_size'], n_out)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for l in self.layers:\n",
    "            x, _ = l(x)    \n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T16:15:43.334751Z",
     "start_time": "2021-01-31T16:15:41.545777Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lmu_params = [dict(input_dim=1, hidden_size=49, order=4, theta=4),\n",
    "              dict(input_dim=49, hidden_size=49, order=4, theta=4),\n",
    "              dict(input_dim=49, hidden_size=49, order=4, theta=4),\n",
    "              dict(input_dim=49, hidden_size=49, order=4, theta=4),\n",
    "             ]\n",
    "model = LMUModel(1, lmu_params).cuda()\n",
    "\n",
    "tot_weights = 0\n",
    "for p in model.parameters():\n",
    "    tot_weights += p.numel()\n",
    "print(\"Total Weights:\", tot_weights)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T16:15:45.466420Z",
     "start_time": "2021-01-31T16:15:45.459513Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def mackey_glass(sample_len=1000, tau=17, delta_t=10, seed=None, n_samples=1):\n",
    "    # Adapted from https://github.com/mila-iqia/summerschool2015/blob/master/rnn_tutorial/synthetic.py\n",
    "    '''\n",
    "    mackey_glass(sample_len=1000, tau=17, seed = None, n_samples = 1) -> input\n",
    "    Generate the Mackey Glass time-series. Parameters are:\n",
    "        - sample_len: length of the time-series in timesteps. Default is 1000.\n",
    "        - tau: delay of the MG - system. Commonly used values are tau=17 (mild \n",
    "          chaos) and tau=30 (moderate chaos). Default is 17.\n",
    "        - seed: to seed the random generator, can be used to generate the same\n",
    "          timeseries at each invocation.\n",
    "        - n_samples : number of samples to generate\n",
    "    '''\n",
    "    history_len = tau * delta_t \n",
    "    # Initial conditions for the history of the system\n",
    "    timeseries = 1.2\n",
    "    \n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        history = collections.deque(1.2 * np.ones(history_len) + 0.2 * \\\n",
    "                                    (np.random.rand(history_len) - 0.5))\n",
    "        # Preallocate the array for the time-series\n",
    "        inp = np.zeros((sample_len,1))\n",
    "        \n",
    "        for timestep in range(sample_len):\n",
    "            for _ in range(delta_t):\n",
    "                xtau = history.popleft()\n",
    "                history.append(timeseries)\n",
    "                timeseries = history[-1] + (0.2 * xtau / (1.0 + xtau ** 10) - \\\n",
    "                             0.1 * history[-1]) / delta_t\n",
    "            inp[timestep] = timeseries\n",
    "        \n",
    "        # Squash timeseries through tanh\n",
    "        inp = np.tanh(inp - 1)\n",
    "        samples.append(inp)\n",
    "    return samples\n",
    "\n",
    "\n",
    "def generate_data(n_batches, length, split=0.5, seed=0,\n",
    "                  predict_length=15, tau=17, washout=100, delta_t=1,\n",
    "                  center=True):\n",
    "    X = np.asarray(mackey_glass(\n",
    "        sample_len=length+predict_length+washout, tau=tau,\n",
    "        seed=seed, n_samples=n_batches))\n",
    "    X = X[:, washout:, :]\n",
    "    cutoff = int(split*n_batches)\n",
    "    if center:\n",
    "        X -= np.mean(X)  # global mean over all batches, approx -0.066\n",
    "    Y = X[:, predict_length:, :]\n",
    "    X = X[:, :-predict_length, :]\n",
    "    assert X.shape == Y.shape\n",
    "    return ((X[:cutoff], Y[:cutoff]),\n",
    "            (X[cutoff:], Y[cutoff:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T16:15:48.056808Z",
     "start_time": "2021-01-31T16:15:45.670627Z"
    }
   },
   "outputs": [],
   "source": [
    "(train_X, train_Y), (test_X, test_Y) = generate_data(128, 5000)\n",
    "dataset = torch.utils.data.TensorDataset(torch.Tensor(train_X).cuda(), torch.Tensor(train_Y).cuda())\n",
    "dataset = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "dataset_valid = torch.utils.data.TensorDataset(torch.Tensor(test_X).cuda(), torch.Tensor(test_Y).cuda())\n",
    "dataset_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=64, shuffle=False)\n",
    "\n",
    "print(train_X.shape, train_Y.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-31T16:16:09.137416Z",
     "start_time": "2021-01-31T16:16:09.127621Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model, ttype, train_loader, test_loader, optimizer, loss_func, epoch, perf_file,\n",
    "          loss_buffer_size=800, batch_size=4, device='cuda',\n",
    "          prog_bar=None, tau=17, pred_len=15):\n",
    "    \n",
    "    assert(loss_buffer_size%batch_size==0)\n",
    "        \n",
    "    losses = []\n",
    "    last_test_perf = 0\n",
    "    best_test_perf = 1000\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_func(out,\n",
    "                         target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        losses = losses[int(-loss_buffer_size/batch_size):]\n",
    "        \n",
    "        if ((batch_idx*batch_size)%loss_buffer_size == 0):\n",
    "            loss_track = {}\n",
    "            last_test_perf = test_model(model, 'cuda', test_loader, \n",
    "                                  )\n",
    "            loss_track['avg_loss'] = np.mean(losses)\n",
    "            loss_track['last_test'] = last_test_perf\n",
    "            loss_track['epoch'] = epoch\n",
    "            loss_track['batch_idx'] = batch_idx\n",
    "            loss_track['tau'] = tau\n",
    "            loss_track['pred_len'] = pred_len\n",
    "            with open(perf_file, 'a+') as fp:\n",
    "                csv_writer = DictWriter(fp, fieldnames=list(loss_track.keys()))\n",
    "                if fp.tell() == 0:\n",
    "                    csv_writer.writeheader()\n",
    "                csv_writer.writerow(loss_track)\n",
    "                fp.flush()\n",
    "            if best_test_perf > last_test_perf:\n",
    "                torch.save(model.state_dict(), perf_file[:-4]+\".pt\")\n",
    "                best_test_perf = last_test_perf\n",
    "        if not (prog_bar is None):\n",
    "            # Update progress_bar\n",
    "            s = \"{}:{} Loss: {:.4f},valid: {:.4f}\"\n",
    "            format_list = [e,batch_idx*batch_size, np.mean(losses), \n",
    "                           last_test_perf]         \n",
    "            s = s.format(*format_list)\n",
    "            prog_bar.set_description(s)\n",
    "                \n",
    "def test_model(model, device, test_loader):\n",
    "    # Test the Model\n",
    "    nrmsd = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            data = x.to(device)\n",
    "            target = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            nrmsd.append(nengolib.signal.nrmse(out.detach().cpu().numpy().flatten(), \n",
    "                                               target=target.detach().cpu().numpy().flatten()))\n",
    "    perf = np.array(nrmsd).mean()\n",
    "    return perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T05:20:46.823977Z",
     "start_time": "2021-02-02T19:40:22.179973Z"
    }
   },
   "outputs": [],
   "source": [
    "start_tau = 17\n",
    "start_pd = 15\n",
    "diffs = [1,2,3,4,5]\n",
    "for diff in diffs:\n",
    "    (train_X, train_Y), (test_X, test_Y) = generate_data(128, 5000, tau=start_tau*diff, \n",
    "                                                         predict_length=start_pd*diff)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(torch.Tensor(train_X).cuda(), torch.Tensor(train_Y).cuda())\n",
    "    dataset = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    dataset_valid = torch.utils.data.TensorDataset(torch.Tensor(test_X).cuda(), torch.Tensor(test_Y).cuda())\n",
    "    dataset_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=64, shuffle=False)\n",
    "    lmu_params = [dict(input_dim=1, hidden_size=49, order=4, theta=4),\n",
    "                  dict(input_dim=49, hidden_size=49, order=4, theta=4),\n",
    "                  dict(input_dim=49, hidden_size=49, order=4, theta=4),\n",
    "                  dict(input_dim=49, hidden_size=49, order=4, theta=4),\n",
    "                 ]\n",
    "    model = LMUModel(1, lmu_params).cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    loss_func = nn.MSELoss()\n",
    "\n",
    "    epochs = 1000\n",
    "    batch_size = 32\n",
    "    progress_bar = tqdm(range(int(epochs)), bar_format='{l_bar}{bar:5}{r_bar}{bar:-5b}')\n",
    "    last_perf = 1000\n",
    "    for e in progress_bar:\n",
    "        train(model, ttype, dataset, dataset_valid, \n",
    "              optimizer, loss_func, batch_size=batch_size, loss_buffer_size=64,\n",
    "              epoch=e, perf_file=join('perf','mackeyglass_lmu_ratio_3.csv'),\n",
    "              prog_bar=progress_bar, tau=start_tau*diff, pred_len=start_pd*diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
